# Music Genre Classification using Audio and Lyrics
Music genre classification is essential in many music streaming platforms, and its use is extended to various applications such as music recommendation systems, content tagging, etc. Classifying genres is a challenging task, as it contains a diverse range of musical genres, mainly when depending on single modality data. Hence, this research is concerned with classifying music genres by integrating audio and lyrics features using the Music4All dataset. The Music4All dataset is utilised to classify the genres using different ML models. First, data preparation is done by some manual cleaning and employing the Proportionate Stratified Sampling method to reduce the large data to smaller data that resembles the information about the original dataset. Then, the data preprocessing for audio and lyrics is carried out to make the data in a suitable format for modeling purposes. Several NLP techniques are used for data cleaning of lyrics. The Recursive Feature Elimination feature selection technique is employed to select the relevant audio features and has employed word embedding techniques such as CBOW, Glove, and Doc2Vec to convert text into numerical vectors. The data is converted into a suitable format, such as a label encoding the target variable, and splitting of data. Once it is all done, the two modalities are fused at the feature level and fed into ML boosting algorithms such as XGBoost, LightBGM, Catboost, Gradient Boosting, and Histgradient Boosting. The MGC is performed with and without feature selection of audio combined with various word embedding methods. Furthermore, the performance of the proposed models is evaluated using several metrics, and it is also suitable for class imbalance. The comparative analysis between the models is performed to find which model contributes best to classifying the genres. The results showed that integrating all the extracted audio features by addressing class imbalance with the Doc2Vec word embedding model by utilizing XGBoost and Histgradient Boosting models achieved an F1 score of 60%, which outperformed other boosting models.
